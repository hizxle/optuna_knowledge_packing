{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Hyperparameter Optimization for Knowledge Update\n",
    "\n",
    "## Минимизация катастрофического забывания при дообучении языковых моделей\n",
    "\n",
    "Этот notebook демонстрирует полный пайплайн оптимизации гиперпараметров LoRA для задачи обновления фактологических знаний с минимизацией катастрофического забывания.\n",
    "\n",
    "**Автор:** Спирин К.Г.  \n",
    "**Организация:** AIRI, Школа Летово  \n",
    "**Дата:** 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Установка зависимостей\n",
    "\n",
    "Установим необходимые библиотеки для работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установим только отсутствующие пакеты (быстрее при повторных запусках)\n",
    "import importlib, subprocess, sys\n",
    "\n",
    "required = [\n",
    "    'unsloth', 'optuna', 'datasets', 'transformers', 'trl', 'torch', 'accelerate',\n",
    "    'matplotlib', 'seaborn', 'pandas', 'numpy', 'tqdm'\n",
    "]\n",
    "\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', pkg])\n",
    "\n",
    "for pkg in required:\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except Exception:\n",
    "        print(f'Installing {pkg}...')\n",
    "        install(pkg)\n",
    "\n",
    "print('Установка зависимостей завершена (или пакеты уже были установлены).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Импорты и настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Опциональные инструменты\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Импорт наших модулей (убедитесь, что файлы присутствуют в рабочей директории)\n",
    "try:\n",
    "    from generate_dataset import DatasetGenerator, GenerationConfig, KnowledgeClassifier\n",
    "    from train_lora import LoRATrainer\n",
    "    from optimization_pipeline import KnowledgeShiftCalculator, run_optimization\n",
    "    from utils import (\n",
    "        plot_optimization_history,\n",
    "        plot_parameter_importance,\n",
    "        plot_param_relationships,\n",
    "        plot_knowledge_shifts,\n",
    "        create_results_summary,\n",
    "        export_best_config\n",
    "    )\n",
    "except Exception as e:\n",
    "    print('Некоторые утилиты не найдены. Убедитесь, что файлы generate_dataset.py, train_lora.py, optimization_pipeline.py и utils.py в той же папке.')\n",
    "    print('Ошибка импорта:', e)\n",
    "\n",
    "# Настройка для воспроизводимости\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Проверка доступности GPU и базовые оптимизации\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Быстрые оптимизации\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # Не делаем deteministic=True чтобы не терять производительность\n",
    "\n",
    "print('\\nИмпорт и первичная настройка завершены.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Загрузка и подготовка данных\n",
    "\n",
    "### 3.1 Загрузка базового датасета\n",
    "\n",
    "Используем предварительно подготовленный датасет с категоризацией знаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета\n",
    "# Если датасет уже есть локально:\n",
    "dataset_path = \"./my_dataset\"\n",
    "if os.path.exists(dataset_path):\n",
    "    try:\n",
    "        dataset = load_from_disk(dataset_path)\n",
    "        print(f\"Dataset loaded from {dataset_path}\")\n",
    "    except Exception as e:\n",
    "        print('Не удалось загрузить датасет из disk:', e)\n",
    "        dataset = None\n",
    "else:\n",
    "    print('Локальный путь не найден, попробуйте загрузить с HuggingFace или сохраните датасет в ./my_dataset')\n",
    "    dataset = None\n",
    "\n",
    "# Или загрузка с HuggingFace (раскомментируйте при необходимости):\n",
    "# dataset = load_dataset(\"s-nlp/Llama-3.1-8B-Instruct-DBpedia-HighlyKnown\")\n",
    "# dataset.save_to_disk(dataset_path)\n",
    "\n",
    "if dataset is not None and 'full' in dataset:\n",
    "    print(f\"Dataset loaded with {len(dataset['full'])} examples\")\n",
    "else:\n",
    "    print('Dataset отсутствует или имеет неожиданную структуру. Убедитесь, что dataset[\"full\"] существует.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Анализ распределения категорий знаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчет категорий\n",
    "if dataset is not None and 'full' in dataset:\n",
    "    categories = [item.get('Category', 'Unknown') for item in dataset['full']]\n",
    "    category_counts = pd.Series(categories).value_counts()\n",
    "\n",
    "    print(\"Распределение категорий знаний:\")\n",
    "    print(category_counts)\n",
    "    print(f\"\\nВсего примеров: {len(categories)}\")\n",
    "else:\n",
    "    print('Пропускаем анализ распределения — датасет не загружен.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация распределения (если есть данные)\n",
    "if 'category_counts' in globals():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Bar plot\n",
    "    category_counts.plot(kind='bar', ax=ax1)\n",
    "    ax1.set_title('Распределение категорий знаний', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Категория', fontsize=12)\n",
    "    ax1.set_ylabel('Количество', fontsize=12)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Pie chart\n",
    "    category_counts.plot(kind='pie', ax=ax2, autopct='%1.1f%%', startangle=90)\n",
    "    ax2.set_title('Процентное соотношение', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('category_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Нет данных для визуализации.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Примеры из каждой категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем примеры из каждой категории\n",
    "if dataset is not None and 'full' in dataset:\n",
    "    examples_by_category = defaultdict(list)\n",
    "    for item in dataset['full']:\n",
    "        cat = item.get('Category', 'Unknown')\n",
    "        if len(examples_by_category[cat]) < 3:\n",
    "            examples_by_category[cat].append(item)\n",
    "\n",
    "    # Выводим примеры\n",
    "    for category in ['HighlyKnown', 'MaybeKnown', 'WeaklyKnown', 'Unknown']:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Категория: {category}\")\n",
    "        print('='*80)\n",
    "        \n",
    "        for i, example in enumerate(examples_by_category.get(category, []), 1):\n",
    "            print(f\"\\nПример {i}:\")\n",
    "            print(f\"  Вопрос: {example.get('question', '')}\")\n",
    "            \n",
    "            # Извлекаем ответ\n",
    "            answer = example.get('answer', '')\n",
    "            if isinstance(answer, dict):\n",
    "                answer_text = answer.get('normalized_aliases', [''])[0] if answer.get('normalized_aliases') else str(answer)\n",
    "            elif isinstance(answer, list) and len(answer) > 0:\n",
    "                answer_text = answer[0].get('normalized_aliases', [''])[0] if isinstance(answer[0], dict) else str(answer[0])\n",
    "            else:\n",
    "                answer_text = str(answer)\n",
    "            \n",
    "            print(f\"  Ответ: {answer_text}\")\n",
    "else:\n",
    "    print('Пропускаем — датасет не загружен.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Генерация baseline датасета\n",
    "\n",
    "Создадим baseline датасет для последующего сравнения после обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВНИМАНИЕ: Этот шаг требует значительного времени (~4-6 часов)\n",
    "# Рекомендуется использовать уже сгенерированный датасет\n",
    "\n",
    "GENERATE_BASELINE = False  # Установите True для генерации\n",
    "\n",
    "if GENERATE_BASELINE:\n",
    "    print(\"Генерация baseline датасета...\")\n",
    "    print(\"ВНИМАНИЕ: Это займет несколько часов!\")\n",
    "    \n",
    "    config = GenerationConfig(\n",
    "        n_shot=4,\n",
    "        n_experiments=10,\n",
    "        batch_size_greedy=256,\n",
    "        batch_size_sample=16\n",
    "    )\n",
    "    \n",
    "    generator = DatasetGenerator(\n",
    "        model_name=\"unsloth/Qwen3-0.6B-Base\",\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    baseline_dataset = generator.generate_dataset(\n",
    "        data_path=\"s-nlp/Llama-3.1-8B-Instruct-DBpedia-HighlyKnown\",\n",
    "        output_path=\"./baseline_dataset\",\n",
    "        use_sampling=False,\n",
    "        max_examples=500\n",
    "    )\n",
    "    \n",
    "    print(\"Baseline датасет сгенерирован!\")\n",
    "else:\n",
    "    print(\"Используем существующий baseline датасет\")\n",
    "    print(\"Убедитесь, что датасет находится в ./baseline_dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Пример обучения одной конфигурации\n",
    "\n",
    "Прежде чем запускать полную оптимизацию, попробуем обучить одну модель с фиксированными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем аргументы для обучения\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_path = \"./my_dataset\"\n",
    "        self.unknown = 500\n",
    "        self.high_known = 1\n",
    "        self.rank = 1\n",
    "        self.learning_rate = 1e-5\n",
    "        self.lora_alpha = 0.1\n",
    "        self.dropout = 0.1\n",
    "        self.seed = 42\n",
    "        self.paraphrase = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "print(\"Конфигурация обучения:\")\n",
    "print(f\"  Rank: {args.rank}\")\n",
    "print(f\"  Learning Rate: {args.learning_rate}\")\n",
    "print(f\"  Alpha: {args.lora_alpha}\")\n",
    "print(f\"  Unknown facts: {args.unknown}\")\n",
    "print(f\"  HighlyKnown facts: {args.high_known}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВНИМАНИЕ: Обучение занимает ~2-3 часа на T4 GPU\n",
    "TRAIN_EXAMPLE = False  # Установите True для обучения\n",
    "\n",
    "if TRAIN_EXAMPLE:\n",
    "    print(\"Начинаем обучение...\")\n",
    "    \n",
    "    trainer = LoRATrainer(args)\n",
    "    stats, model_path = trainer.train()\n",
    "    \n",
    "    print(f\"\\nОбучение завершено!\")\n",
    "    print(f\"Модель сохранена в: {model_path}\")\n",
    "else:\n",
    "    print(\"Обучение пропущено. Установите TRAIN_EXAMPLE=True для запуска.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Вычисление Knowledge Shifts\n",
    "\n",
    "Демонстрация работы калькулятора knowledge shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем калькулятор\n",
    "try:\n",
    "    shift_calculator = KnowledgeShiftCalculator()\n",
    "    \n",
    "    print(\"Веса для различных типов сдвигов:\")\n",
    "    print(\"\\nПозитивные сдвиги (желательные):\")\n",
    "    print(f\"  UK → HK: +{shift_calculator.shift_types['UK_to_HK']} (полное усвоение нового факта)\")\n",
    "    print(f\"  UK → MK: +{shift_calculator.shift_types['UK_to_MK']} (частичное усвоение)\")\n",
    "    print(f\"  MK → HK: +{shift_calculator.shift_types['MK_to_HK']} (улучшение частично известного)\")\n",
    "    \n",
    "    print(\"\\nНегативные сдвиги (нежелательные):\")\n",
    "    print(f\"  HK → UK: {shift_calculator.shift_types['HK_to_UK']} (катастрофическое забывание)\")\n",
    "    print(f\"  HK → MK: {shift_calculator.shift_types['HK_to_MK']} (частичная деградация)\")\n",
    "    print(f\"  MK → UK: {shift_calculator.shift_types['MK_to_UK']} (потеря частичных знаний)\")\n",
    "except Exception as e:\n",
    "    print('Не удалось создать KnowledgeShiftCalculator — убедитесь, что optimization_pipeline.py присутствует и содержит соответствующий класс.')\n",
    "    print('Ошибка:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример вычисления shifts (если есть обученная модель)\n",
    "CALCULATE_SHIFTS = False  # Установите True если есть данные\n",
    "\n",
    "if CALCULATE_SHIFTS:\n",
    "    # Пути к датасетам\n",
    "    baseline_path = \"./baseline_dataset\"\n",
    "    after_training_path = \"./after_training_dataset\"\n",
    "    \n",
    "    # Вычисляем сдвиги\n",
    "    shifts = shift_calculator.calculate_shifts_from_datasets(\n",
    "        baseline_path, \n",
    "        after_training_path\n",
    "    )\n",
    "    \n",
    "    # Вычисляем score\n",
    "    score = shift_calculator.calculate_objective_score(shifts)\n",
    "    \n",
    "    print(\"\\nРезультаты Knowledge Shifts:\")\n",
    "    print(\"=\"*50)\n",
    "    for shift_type, count in shifts.items():\n",
    "        weight = shift_calculator.shift_types.get(shift_type, 0)\n",
    "        print(f\"{shift_type}: {count} (вес: {weight})\")\n",
    "    \n",
    "    print(f\"\\nИтоговый weighted score: {score:.3f}\")\n",
    "    \n",
    "    # Визуализация\n",
    "    plot_knowledge_shifts(shifts, save_path='example_shifts.png')\n",
    "else:\n",
    "    print(\"Вычисление shifts пропущено. Требуются baseline и post-training датасеты.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Запуск оптимизации гиперпараметров\n",
    "\n",
    "### 7.1 Настройка оптимизации\n",
    "\n",
    "**ВНИМАНИЕ:** Полная оптимизация с 28 trials требует ~70-80 часов GPU времени!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры оптимизации\n",
    "BASE_DATASET = \"./baseline_dataset\"\n",
    "TEST_QUESTIONS = \"s-nlp/Llama-3.1-8B-Instruct-DBpedia-HighlyKnown\"\n",
    "OUTPUT_DIR = \"./optimization_results\"\n",
    "N_TRIALS = 28  # Уменьшите для быстрого тестирования\n",
    "STUDY_NAME = \"lora_optimization\"\n",
    "\n",
    "print(f\"Параметры оптимизации:\")\n",
    "print(f\"  Количество trials: {N_TRIALS}\")\n",
    "print(f\"  База данных: {OUTPUT_DIR}/optuna.db\")\n",
    "print(f\"  Примерное время: ~{N_TRIALS * 2.5:.1f} часов\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАПУСК ОПТИМИЗАЦИИ\n",
    "RUN_OPTIMIZATION = False  # Установите True для запуска\n",
    "\n",
    "if RUN_OPTIMIZATION:\n",
    "    print(\"Запуск оптимизации...\")\n",
    "    print(\"Это займет значительное время. Прогресс будет логироваться.\")\n",
    "    \n",
    "    study = run_optimization(\n",
    "        base_dataset_path=BASE_DATASET,\n",
    "        test_questions_path=TEST_QUESTIONS,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        n_trials=N_TRIALS,\n",
    "        study_name=STUDY_NAME\n",
    "    )\n",
    "    \n",
    "    print(\"\\nОптимизация завершена!\")\n",
    "else:\n",
    "    print(\"Оптимизация пропущена.\")\n",
    "    print(\"Для запуска установите RUN_OPTIMIZATION=True\")\n",
    "    print(\"\\nДля загрузки существующего study используйте:\")\n",
    "    print(\"study = optuna.load_study(study_name=STUDY_NAME, storage=...)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Загрузка результатов оптимизации\n",
    "\n",
    "Если оптимизация уже проведена, загрузим результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка существующего study\n",
    "try:\n",
    "    storage = f\"sqlite:///{OUTPUT_DIR}/optuna.db\"\n",
    "    study = optuna.load_study(\n",
    "        study_name=STUDY_NAME,\n",
    "        storage=storage\n",
    "    )\n",
    "    \n",
    "    print(f\"Study загружен успешно!\")\n",
    "    print(f\"Количество trials: {len(study.trials)}\")\n",
    "    print(f\"Лучший score: {study.best_value:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Не удалось загрузить study: {e}\")\n",
    "    print(\"Запустите оптимизацию или проверьте путь к базе данных\")\n",
    "    study = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Анализ результатов оптимизации\n",
    "\n",
    "### 8.1 Общая статистика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if study is not None:\n",
    "    # Лучший trial\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ЛУЧШАЯ КОНФИГУРАЦИЯ\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTrial номер: {best_trial.number}\")\n",
    "    print(f\"Score: {best_trial.value:.4f}\")\n",
    "    print(\"\\nГиперпараметры:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    if best_trial.user_attrs:\n",
    "        print(\"\\nДополнительные метрики:\")\n",
    "        for key, value in best_trial.user_attrs.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Экспорт конфигурации\n",
    "    try:\n",
    "        export_best_config(study, f\"{OUTPUT_DIR}/best_config.json\")\n",
    "    except Exception:\n",
    "        print('Не удалось экспортировать конфигурацию — проверьте, доступна ли функция export_best_config')\n",
    "else:\n",
    "    print(\"Study не загружен. Пропускаем анализ.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 История оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if study is not None:\n",
    "    plot_optimization_history(study, save_path=f\"{OUTPUT_DIR}/optimization_history.png\")\n",
    "else:\n",
    "    print(\"Study не загружен\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Важность параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if study is not None:\n",
    "    plot_parameter_importance(study, save_path=f\"{OUTPUT_DIR}/parameter_importance.png\")\n",
    "else:\n",
    "    print(\"Study не загружен\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Влияние отдельных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if study is not None:\n",
    "    # Анализ влияния rank\n",
    "    plot_param_relationships(study, 'rank', save_path=f\"{OUTPUT_DIR}/rank_effect.png\")\n",
    "    \n",
    "    # Анализ влияния learning_rate\n",
    "    plot_param_relationships(study, 'learning_rate', save_path=f\"{OUTPUT_DIR}/lr_effect.png\")\n",
    "    \n",
    "    # Анализ влияния alpha\n",
    "    plot_param_relationships(study, 'lora_alpha', save_path=f\"{OUTPUT_DIR}/alpha_effect.png\")\n",
    "else:\n",
    "    print(\"Study не загружен\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Таблица всех результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if study is not None:\n",
    "    # Создаем сводную таблицу\n",
    "    results_df = create_results_summary(study)\n",
    "    \n",
    "    # Показываем топ-10 trials\n",
    "    print(\"\\nТОП-10 КОНФИГУРАЦИЙ:\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    display_cols = ['number', 'value', 'params_rank', 'params_learning_rate', 'params_lora_alpha']\n",
    "    if 'user_attrs_positive_shifts' in results_df.columns:\n",
    "        display_cols.extend(['user_attrs_positive_shifts', 'user_attrs_negative_shifts'])\n",
    "    \n",
    "    available_cols = [col for col in display_cols if col in results_df.columns]\n",
    "    print(results_df.head(10)[available_cols].to_string(index=False))\n",
    "    \n",
    "    # Сохраняем полную таблицу\n",
    "    results_df.to_csv(f\"{OUTPUT_DIR}/all_results.csv\", index=False)\n",
    "    print(f\"\\nПолная таблица сохранена в {OUTPUT_DIR}/all_results.csv\")\n",
    "else:\n",
    "    print(\"Study не загружен\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Практические рекомендации\n",
    "\n",
    "На основе проведенных экспериментов можно сформулировать следующие рекомендации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if study is not None:\n",
    "    try:\n",
    "        best_params = study.best_params\n",
    "    except Exception:\n",
    "        best_params = None\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ПРАКТИЧЕСКИЕ РЕКОМЕНДАЦИИ\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if best_params is not None:\n",
    "        print(\"\\n1. ОПТИМАЛЬНЫЕ ГИПЕРПАРАМЕТРЫ для обновления фактологических знаний:\")\n",
    "        print(f\"   - Rank: {best_params.get('rank')}\")\n",
    "        print(f\"   - Learning Rate: {best_params.get('learning_rate')}\")\n",
    "        print(f\"   - Alpha: {best_params.get('lora_alpha')}\")\n",
    "    else:\n",
    "        print('Нет доступных лучших параметров — загрузите study.')\n",
    "    \n",
    "    print(\"\\n2. ОБЩИЕ ПРИНЦИПЫ:\")\n",
    "    print(\"   - Используйте минимально возможный rank и small alpha для уменьшения вмешательства в базовую модель.\")\n",
    "    print(\"   - Применяйте небольшой learning rate (1e-5 .. 5e-5) и короткие эпохи при LoRA дообучении для снижения забывания.\")\n",
    "    print(\"   - Тестируйте на baseline датасете, чтобы контролировать деградацию производительности.\")\n",
    "else:\n",
    "    print(\"Study не загружен — рекомендации ограничены.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Быстрые улучшения и переключатели для тестирования\n",
    "\n",
    "Эти флаги позволяют быстро запустить упрощённую версию pipeline для проверки, не тратя часы GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Быстрые переключатели\n",
    "QUICK_DEBUG = True   # Уменьшает N_TRIALS и примеры для быстрого прогона\n",
    "USE_AMP = True       # Использовать смешанную точность (если доступно)\n",
    "\n",
    "if QUICK_DEBUG:\n",
    "    print('QUICK_DEBUG включён — уменьшаем нагрузку.')\n",
    "    N_TRIALS = 4\n",
    "    # Можно ограничить количество примеров при генерации/оценке\n",
    "    MAX_EXAMPLES_QUICK = 50\n",
    "\n",
    "if USE_AMP and torch.cuda.is_available():\n",
    "    print('Mixed precision enabled (используйте torch.cuda.amp в обучении)')\n",
    "else:\n",
    "    print('Mixed precision недоступна или отключена.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
